{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn, pennylane, matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing kernel methods and variational quantum circuits on a real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbltostibalduc/miniforge3/envs/plTutorialsEnv/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "from pennylane.operation import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a random number generator for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# pick only the first two classes (corresponding to the first 100 samples)\n",
    "X = X[:100]\n",
    "y = y[:100]\n",
    "\n",
    "# scaling the data for better training and avoiding problems due to periodic encoding\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# move labels from [0, 1] to [-1, 1] range\n",
    "y_scaled = 2 * (y - 0.5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact amplitude encoding may require up to an exponential amount of operations and thus it does not work for NISQ. We can do another type of encoding, i.e. *angle encoding*, for which the features are encoded in as many qubits and each of them is used as a rotation angle of a gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that encodes each of the features as a $R_Z$ rotation for each qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_encoding_rz(x):\n",
    "    \"\"\"Encodes features as Z-rotations\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): data point where the entries are the features to be encoded\n",
    "    \"\"\"\n",
    "    # ================\n",
    "    # YOUR CODE BELOW\n",
    "    # ================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In quantum kernel methods, the quantum computer is used exclusively to compute the kernel matrix. \n",
    "\n",
    "Remember that the kernel is given by the inner product of two samples $x_1$ and $x_2$. More correctly, it is the inner product between their mappings in the higher-dimensional feature space, thus $\\phi(x_1)$ and $\\phi(x_2)$. For us, this higher-dimensional mapping is given by our $R_Z$-encoding, which leads to the states $|\\phi(x_1)\\rangle$ and $|\\phi(x_2)\\rangle$. Therefore, we want to compute $|\\langle \\phi(x_2) | \\phi(x_1) \\rangle|^2$ (the square matters because the kernel is a measure of a distance).\n",
    "\n",
    "It is easy to verify that the circuit used to compute the kernel is\n",
    "\n",
    "<img src=\"kernel.jpg\" alt=\"kernel\" width=\"200\"/>\n",
    "\n",
    "where $\\Phi(x)$ computes the feature map and the final measuerement is on the all-zeros projector $|0\\dots 0\\rangle\\langle 0\\dots 0|$ (equivalent to computing the probability of measuring the all-zeros state)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ba57309a75c1f2334b12eaf868931394174054c28fafce8b57219f88302837c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('plTutorialsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
