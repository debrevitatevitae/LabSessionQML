{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the parity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to prepare the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    \"\"\"Applies a layer of arbitrary rotations and circular entanglements to the variational circuit\n",
    "\n",
    "    Args:\n",
    "        W (np.ndarray): rotation parameters for the layer\n",
    "    \"\"\"\n",
    "    for i in range(n_qubits):\n",
    "        qml.Rot(W[i, 0], W[i, 1], W[i, 2], wires=i)\n",
    "\n",
    "    for i in range(n_qubits-1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "    if n_qubits > 2:\n",
    "        qml.CNOT(wires=[n_qubits-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statepreparation(x):\n",
    "    \"\"\"Prepares the binary state fed to the vqc\n",
    "\n",
    "    Args:\n",
    "        x (List): list of 0s and 1s corresponding to the basis state\n",
    "    \"\"\"\n",
    "    qml.BasisState(x, wires=[i for i in range(n_qubits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `qnode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: fill-in the following function with the state preparation routine and the layer routine. The weight array should be an array of 2D arrays. Each of the sub-array contains the parameters of a layer. Make sure to compute the expectation value of the $Z$ gate on qubit 0. Refer to [this link](https://pennylane.readthedocs.io/en/stable/code/api/pennylane.expval.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    \"\"\"Generates the trainable quantum circuit with binary input\n",
    "\n",
    "    Args:\n",
    "        weights (List[np.ndarray]): all the variational parameters, one\n",
    "            array per layer\n",
    "        x (List): binaries representing the input\n",
    "    \"\"\"\n",
    "    # ================\n",
    "    # YOUR CODE BELOW\n",
    "    # ================\n",
    "    return #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a classical bias parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    \"\"\"Complete variational classifier, including a bias\n",
    "\n",
    "    Args:\n",
    "        weights (List[np.ndarray]): all the variational parameters, one\n",
    "            array per layer\n",
    "        bias (float): classical bias value, added to the output of the quantum circuit\n",
    "        x (List): binaries representing the input\n",
    "    \"\"\"\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    \"\"\"Computes the MSE between labels and predictions\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): actual values\n",
    "        predictions (List[int]): model predictions\n",
    "\n",
    "    Returns:\n",
    "        float: value of the MSE\n",
    "    \"\"\"\n",
    "    loss = 0.\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss += (l - p) ** 2\n",
    "\n",
    "    loss /= len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    \"\"\"Returns the accuracy over the dataset\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): true values\n",
    "        predictions (List[int]): model-predicted values\n",
    "\n",
    "    Returns:\n",
    "        float: number of accurate predictions over total\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss += 1\n",
    "\n",
    "    loss /= len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: complete the cost function computing the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    \"\"\"Computes the predictions and returns the MSE over the dataset\n",
    "\n",
    "    Args:\n",
    "        weights (List[np.ndarray]): all the variational parameters, one\n",
    "            array per layer\n",
    "        bias (float): classical bias value, added to the output of the quantum circuit\n",
    "        X (List[List]): list of all the binary input strings\n",
    "        Y (List): labels\n",
    "\n",
    "    Returns:\n",
    "        float: MSE over the dataset\n",
    "    \"\"\"\n",
    "    # ================\n",
    "    # YOUR CODE BELOW\n",
    "    # ================\n",
    "    return #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"variational_classifier/data/parity.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[:, :-1], requires_grad=False)\n",
    "Y = np.array(data[:, -1], requires_grad=False)\n",
    "\n",
    "# shift lables from [0, 1] to [-1, 1], to match the range of expectation values\n",
    "Y = 2 * Y - np.ones(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "num_layers = 2\n",
    "weights_init = .01 * rng.normal(size=(num_layers, n_qubits, 3), requires_grad=True)\n",
    "bias_init = np.array(0., requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining optimizer and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(.5)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "iterations = 25\n",
    "\n",
    "for it in range(iterations):\n",
    "\n",
    "    # shuffle the batch indices\n",
    "    batch_index = rng.integers(0, len(X), size=batch_size)\n",
    "\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "\n",
    "    # update weights and biases\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ba57309a75c1f2334b12eaf868931394174054c28fafce8b57219f88302837c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('plTutorialsEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
